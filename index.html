<!DOCTYPE html>
<html lang="en">

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Yuetao  Chen


</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="/assets/css/bootstrap.min.css" rel="stylesheet">
<link rel="stylesheet" href="/assets/css/mdb.min.css">

<!-- Fonts & Icons -->
<link rel="stylesheet" href="/assets/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="/assets/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<!-- <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" /> -->

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>🚲</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="www.chenyuetao.tech/">



    <!--  -->
  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>
    
    <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?29274d0e68415cd4179a801ea4abf7cb";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Yuetao</span>   Chen
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item dropdown ">
              <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                CV
                
              </a>
              <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
              
              
                <a class="dropdown-item" href="/assets/files/cv.pdf">PDF</a>
              
              
              </div>
          </li>
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                Publications
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/research/">
                Research
                
              </a>
          </li>
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    
    <div class="profile float-left">
      
      
    </div>
    
    <h1 class="post-title" style="font-size:28px">
     <span class="font-weight-bold">Yuetao</span>  Chen
    </h1>
     <p class="desc"></p>
  

  <article>
    
  </article></header>

    <div class="clearfix">
      <p><b>Master Student, Institute of Computing Technology, Chinese Academy of Sciences</b><br>
No.6 Kexueyuan South Road, Zhongguancun, Haidian District, Beijing, China<br>
<b>y_t_chen [at] outlook.com, chenyuetao21s [at] ict.ac.cn</b><br>
<a href="https://www.chenyuetao.tech/assets/img/qr.png" target="_blank" rel="noopener noreferrer">Wechat</a> || <a href="https://www.chenyuetao.tech/assets/files/cv.pdf" target="_blank" rel="noopener noreferrer">CV</a></p>

<p>I’m currently a Master student at Institute of Computing Technology, Chinese Academy of Sciences (ICT, CAS), advised by Professor Lei Liu &amp; Li Chen. Previously,  I was an undergraduate student at Beijing Jiaotong University &amp; Lancaster University. Please refer to my <a href="https://www.chenyuetao.tech/assets/files/cv.pdf" target="_blank" rel="noopener noreferrer">CV</a>.</p>

<p>I’m applying to Ph.D (2024 Fall).</p>

    </div>

    

    <h4 id="highlights"><strong><font color="3333FF">Research interest</font></strong></h4>

<ol style="list-style-type:upper-roman">
  <li><b>High performance computing (including multicore CPUs, SIMD, GPU, etc.)</b></li>
  <li><b>ML for system &amp; system for ML</b></li>
  <li><b>I am also interested in other areas of systems and have read papers on related topics such as memory management.</b></li>
</ol>

<!-- <h4 id="preprints">Preprints</h4>

<ol>

  <li>Yidong Wang, Hao Chen, Qiang Heng, Wenxin Hou, Marios Savvides, Takahiro Shinozaki, Bhiksha Raj, Zhen WuBowen Zhang, Wenxin Hou, Zhen Wu, <u>Jindong Wang</u><sup>#</sup>. FreeMatch: Self-adaptive Thresholding for Semi-supervised Learning. arXiv preprint arXiv:2205.07246. [<a href="https://arxiv.org/abs/2205.07246"
    target="_blank" rel="noopener noreferrer">arXiv</a>]</li>

  <li>Yidong Wang, Bowen Zhang, Wenxin Hou, Zhen Wu, <u>Jindong Wang</u><sup>#</sup>, Takahiro Shinozaki. Margin Calibration for Long-Tailed Visual Recognition. arXiv preprint arXiv:2112.07225. [<a href="https://arxiv.org/abs/2112.07225"
      target="_blank" rel="noopener noreferrer">arXiv</a>]</li>

  <li>
    <u>Jindong Wang</u>, Wenjie Feng, Chang Liu, Chaohui Yu, Mingxuan Du, Renjun Xu, Tao Qin, and Tie-Yan Liu. Learning
    Invariant Representations across Domains and Tasks. arXiv preprint arXiv:2103.05114. [<a
      href="https://arxiv.org/abs/2103.05114" target="_blank" rel="noopener noreferrer">arXiv</a>]
  </li>
  <li>Chaohui Yu, <u>Jindong Wang</u><sup>#</sup>, Chang Liu, Tao Qin, Renjun Xu, Wenjie Feng, Yiqiang Chen, and Tie-Yan
    Liu. Learning to match distributions for domain adaptation. arXiv preprint arXiv:2007.10791. [<a
      href="http://arxiv.org/abs/https://arxiv.org/abs/2007.10791" target="_blank" rel="noopener noreferrer">arXiv</a>]
  </li>
</ol> -->

    
      <div class="publications">
  <h4><strong><font color="3333FF">Publications</font></strong></h4>
  * indicates the corresponding author.
  <ol class="bibliography">
<li>
<!-- <div class="row"> -->
  <!-- <div class="col-sm-1 abbr">
  
    
    <abbr class="badge">arXiv(submitted to SOSP)</abbr>
    
  
  </div> -->

  <div id="li2023gamify" class="col-sm-8" style="max-width: 100%;">
    
      <div class="title" style="padding-top: 0em; padding-bottom: 0px; margin-bottom: 0em;">
<font color="6600CC"><b>[arXiv(submitted to SOSP)]</b></font> Gamify Stencil Dwarf on Cloud for Democratizing Scientific Computing </div>
      <div class="author" style="padding-top: 0em; padding-bottom: 0px; margin-bottom: 0em;">
        
          
          
          
          
          
          
            
              
                
                  Kun Li,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Zhichun Li,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  <em><b>Yuetao Chen</b></em>
                ,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Zixuan Wang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yiwei Zhang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Liang Yuan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Haipeng Jia,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yunquan Zhang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ting Cao*,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Mao. Yang
                
              
            
          
        
      </div>

      <div style="padding-top: 0em; padding-bottom: 0px; margin-bottom: -.1em;">
      
        <em>arXiv preprint (submitted to SOSP 2023)</em>
      
      
        2023
      

      | [
        
        <!--  -->
        
          <a href="https://arxiv.org/abs/2303.08365" style="padding-top: 0em; padding-bottom: 0px;" target="_blank" rel="noopener noreferrer">HTML</a>
        
        
          
          <a href="/assets/files/tetris.pdf" style="padding-top: 0em; padding-bottom: 0px;">PDF</a>
          
        
        
        
        
        
        
        
        
    
        
        ]

      </div>
      
    

    <!-- <div class="links" style="padding-top: 0em; padding-bottom: 0em; height: 30px; margin-bottom: -.5em;"> -->
    <!-- 
      <a class="abstract btn btn-sm z-depth-0" role="button" style="padding-top: 0em; padding-bottom: 0px;">Abs</a>
     -->
    
    <!-- </div> -->

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Stencil computation is one of the most important kernels in various scientific computing. Nowadays, most Stencil-driven scientific computing still relies heavily on supercomputers, suffering from expensive access, poor scalability, and duplicated optimizations. This paper proposes Tetris, the first system for high-performance Stencil on heterogeneous CPU+GPU, towards democratizing Stencil-driven scientific computing on Cloud. In Tetris, polymorphic tiling tetrominoes are first proposed to bridge different hardware architectures and various application contexts with a perfect spatial and temporal tessellation automatically. Tetris is contributed by three main components: (1) Underlying hardware characteristics are first captured to achieve a sophisticated Pattern Mapping by register-level tetrominoes; (2) An efficient Locality Enhancer is first presented for data reuse on spatial and temporal dimensions simultaneously by cache/SMEM-level tetrominoes; (3) A novel Concurrent Scheduler is first designed to exploit the full potential of on-cloud memory and computing power by memory-level tetrominoes. Tetris is orthogonal to (and complements) the optimizations or deployments for a wide variety of emerging and legacy scientific computing applications. Results of thermal diffusion simulation demonstrate that the performance is improved by 29.6x, reducing time cost from day to hour, while preserving the original accuracy.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
<!-- </div> -->
</li>
<li>
<!-- <div class="row"> -->
  <!-- <div class="col-sm-1 abbr">
  
    
    <abbr class="badge">FAST 23</abbr>
    
  
  </div> -->

  <div id="liu2023intelligent" class="col-sm-8" style="max-width: 100%;">
    
      <div class="title" style="padding-top: 0em; padding-bottom: 0px; margin-bottom: 0em;">
<font color="6600CC"><b>[FAST 23]</b></font> Intelligent Resource Scheduling for Co-located Latency-critical Services: A Multi-Model Collaborative Learning Approach </div>
      <div class="author" style="padding-top: 0em; padding-bottom: 0px; margin-bottom: 0em;">
        
          
          
          
          
          
          
            
              
                
                  Lei Liu*,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Xinglei Dou,
                
              
            
          
        
          
          
          
          
          
          
            
              
                and <em><b>Yuetao Chen</b></em>
              
            
          
        
      </div>

      <div style="padding-top: 0em; padding-bottom: 0px; margin-bottom: -.1em;">
      
        <em>21st USENIX Conference on File and Storage Technologies (FAST 23)</em>
      
      
        2023
      

      | [
        
        <!--  -->
        
          <a href="https://www.usenix.org/conference/fast23/presentation/liu" style="padding-top: 0em; padding-bottom: 0px;" target="_blank" rel="noopener noreferrer">HTML</a>
        
        
          
          <a href="/assets/files/fast23.pdf" style="padding-top: 0em; padding-bottom: 0px;">PDF</a>
          
        
        
        
        
        
        
        
        
    
        
        ]

      </div>
      
    

    <!-- <div class="links" style="padding-top: 0em; padding-bottom: 0em; height: 30px; margin-bottom: -.5em;"> -->
    <!-- 
      <a class="abstract btn btn-sm z-depth-0" role="button" style="padding-top: 0em; padding-bottom: 0px;">Abs</a>
     -->
    
    <!-- </div> -->

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Latency-critical services have been widely deployed in cloud environments. For cost-efficiency, multiple services are usually co-located on a server. Thus, run-time resource scheduling becomes the pivot for QoS control in these complicated co-location cases. However, the scheduling exploration space enlarges rapidly with the increasing server resources, making the schedulers hardly provide ideal solutions quickly. More importantly, we observe that there are “resource cliffs” in the scheduling exploration space. They affect the exploration efficiency and always lead to severe QoS fluctuations in previous schedulers. To address these problems, we propose a novel ML-based intelligent scheduler – OSML. It learns the correlation between architectural hints (e.g., IPC, cache misses, memory footprint, etc.), scheduling solutions and the QoS demands based on a data set we collected from 11 widely deployed services running on off-the-shelf servers. OSML employs multiple ML models to work collaboratively to predict QoS variations, shepherd the scheduling, and recover from QoS violations in complicated co-location cases. OSML can intelligently avoid resource cliffs during scheduling and reach an optimal solution much faster than previous approaches for co-located LC services. Experimental results show that OSML supports higher loads and meets QoS targets with lower scheduling overheads and shorter convergence time than previous studies.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
<!-- </div> -->
</li>
<li>
<!-- <div class="row"> -->
  <!-- <div class="col-sm-1 abbr">
  
    
    <abbr class="badge">CCF THPC</abbr>
    
  
  </div> -->

  <div id="chen2022smart" class="col-sm-8" style="max-width: 100%;">
    
      <div class="title" style="padding-top: 0em; padding-bottom: 0px; margin-bottom: 0em;">
<font color="6600CC"><b>[CCF THPC]</b></font> Smart scheduler: an adaptive NVM-aware thread scheduling approach on NUMA systems </div>
      <div class="author" style="padding-top: 0em; padding-bottom: 0px; margin-bottom: 0em;">
        
          
          
          
          
          
          
            
              
                
                  <em><b>Yuetao Chen</b></em>
                ,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Keni Qiu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Li Chen,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Haipeng Jia,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yunquan Zhang,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Limin Xiao,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Lei Liu*
                
              
            
          
        
      </div>

      <div style="padding-top: 0em; padding-bottom: 0px; margin-bottom: -.1em;">
      
        <em>CCF Transactions on High Performance Computing</em>
      
      
        2022
      

      | [
        
        <!--  -->
        
          <a href="https://link.springer.com/article/10.1007/s42514-022-00110-2" style="padding-top: 0em; padding-bottom: 0px;" target="_blank" rel="noopener noreferrer">HTML</a>
        
        
          
          <a href="/assets/files/ccfthpc.pdf" style="padding-top: 0em; padding-bottom: 0px;">PDF</a>
          
        
        
        
        
        
        
        
        
    
        
        ]

      </div>
      
    

    <!-- <div class="links" style="padding-top: 0em; padding-bottom: 0em; height: 30px; margin-bottom: -.5em;"> -->
    <!-- 
      <a class="abstract btn btn-sm z-depth-0" role="button" style="padding-top: 0em; padding-bottom: 0px;">Abs</a>
     -->
    
    <!-- </div> -->

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>NVM provides large memory capacity, long-term data durability, and high memory bandwidth for multi-thread applications on cloud servers. Nowadays, cloud servers often employ NUMA architecture, where the thread scheduling mechanism plays a vital role in overall system performance because of the NUMA property. However, with the increase in server resources’ diversity, i.e., hybrid memory systems using DRAM and NVM on NUMA nodes, the exploration space for thread scheduling is expanding rapidly. Unfortunately, the existing thread schedulers, including rule-based algorithms and scheduling domain methods, cannot provide ideal scheduling solutions in such complicated cases. And, those thread schedulers neglect customized heterogeneous memory structures, thus degrading overall system performance. Fortunately, reinforcement learning can choose actions with maximum rewards values in a specific environment, leading the scheduler towards an optimal solution. In this paper, we propose a thread scheduling approach, i.e., Smart Scheduler, by leveraging a reinforcement learning method. Smart Scheduler takes OS event information as input, extends LinUCB to explore the scheduling space, and guides thread-level scheduling. We evaluate Smart Scheduler on the off-the-shelf server equipped with NVM. The experimental results show that the proposed Smart Scheduler can converge faster (usually within 20 actions) than rule-based algorithms and scheduling domain methods and reduce program execution time by up to 59.9%. It also outperforms rule-based algorithms and scheduling domain methods by 4.1% and 19.1% in quality of service latency.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
<!-- </div> -->
</li>
<li>
<!-- <div class="row"> -->
  <!-- <div class="col-sm-1 abbr">
  
    
    <abbr class="badge">JCRD</abbr>
    
  
  </div> -->

  <div id="2021-09-1856" class="col-sm-8" style="max-width: 100%;">
    
      <div class="title" style="padding-top: 0em; padding-bottom: 0px; margin-bottom: 0em;">
<font color="6600CC"><b>[JCRD]</b></font> An Investigation into Quantum Program Mapping on Superconducting Quantum Computers </div>
      <div class="author" style="padding-top: 0em; padding-bottom: 0px; margin-bottom: 0em;">
        
          
          
          
          
          
          
            
              
                
                  Xinglei Dou,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lei Liu*,
                
              
            
          
        
          
          
          
          
          
          
            
              
                and <em><b>Yuetao Chen</b></em>
              
            
          
        
      </div>

      <div style="padding-top: 0em; padding-bottom: 0px; margin-bottom: -.1em;">
      
        <em>Journal of Computer Research and Development (In Chinese)</em>
      
      
        2021
      

      | [
        
        <!--  -->
        
          <a href="https://crad.ict.ac.cn/en/article/doi/10.7544/issn1000-1239.2021.20210314" style="padding-top: 0em; padding-bottom: 0px;" target="_blank" rel="noopener noreferrer">HTML</a>
        
        
          
          <a href="/assets/files/JCRD-2021.pdf" style="padding-top: 0em; padding-bottom: 0px;">PDF</a>
          
        
        
        
        
        
        
        
        
    
        
        ]

      </div>
      
    

    <!-- <div class="links" style="padding-top: 0em; padding-bottom: 0em; height: 30px; margin-bottom: -.5em;"> -->
    <!-- 
      <a class="abstract btn btn-sm z-depth-0" role="button" style="padding-top: 0em; padding-bottom: 0px;">Abs</a>
     -->
    
    <!-- </div> -->

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Errors occur due to noise when quantum programs are running on a quantum computer. Previous quantum program mapping solutions map a specific quantum program onto the most reliable region on a quantum computer for higher fidelity. Mapping multiple quantum programs onto a specific quantum computer simultaneously improves the throughput and resource utilization of the quantum computer. However, due to the scarcity of robust resources and resource allocation conflict, multi-programming on quantum computers leads to a decline in overall fidelity. We introduce quantum program mapping, classify the related studies, and analyze their characteristics and differences. Furthermore, we propose a new mapping solution for mapping concurrent quantum programs, including three key designs. 1) We propose a community detection assisted qubit partition (CDAQP) algorithm, which partitions physical qubits for concurrent quantum programs according to both physical topology and the error rates, improving the reliability of initial mapping and avoiding the waste of robust resources. 2) We introduce inter-program SWAPs, reducing the mapping overheads of concurrent quantum programs. 3) A framework for scheduling quantum program mapping tasks is proposed, which dynamically selects concurrent quantum programs to be executed, improving the throughput while ensuring the fidelity of the quantum computers. Our approach improves the fidelity by 8.6% compared with the previous solution while reducing the mapping overheads by 11.6%. Our system is a prototype of the OS for quantum computers—QuOS.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
<!-- </div> -->
</li>
</ol>
</div>

    

    <h4 id="research"><strong><font color="3333FF">Research</font></strong></h4>

<h6 id="-bridging-the-gap-between-stencil-and-convolution-"><strong>Bridging the Gap Between Stencil and Convolution</strong></h6>
<p>Advisor: Dr. Kun Li | Microsoft Research Asia</p>
<p>This project analyzed the similarities and differences between stencils and convolutions and optimized them for acceleration on GPUs based on the characteristics of GPU hardware. </p>
<ul>
<li>Currently, I have developed and proposed a new Tensor core algorithm for stencil computing, based on the img2col approach, that leverages Tensor core processing power for single-channel computations.</li>
</ul>
<h6 id="-stencil-computing-on-heterogeneous-platform-"><strong>Stencil Computing on Heterogeneous Platform</strong></h6>
<p>Advisor: Dr. Kun Li | Microsoft Research Asia</p>
<p>It is the first system for high-performance Stencil on heterogeneous CPU+GPU with novel optimizations on both CPU and GPU. It leverages Pattern Mapping by Register-level Tetrominoes to efficiently utilize SIMD on CPUs and Tensor Cores on GPUs. It also leverages locality by cache/SMEM-level tetrominoes and implement CPU and GPU Collaboration.</p>
<ul>
<li>Implemented a new CPU SIMD register level algorithm for stencil computing, resulting in significant performance improvements of 6.3% - 19.9% on different stencil kernel shapes.</li>
<li>Replicated the tessellate tiling (SC '17) to be coordinated with SIMD algorithm.</li>
<li>
<p>Designed a data exchange method between CPU and GPU for stencil computation which covers the communication latency by computation.</p>
</li>
<li>
<p><strong>[arXiv (submitted to SOSP)]</strong> <a href="https://arxiv.org/pdf/2303.08365.pdf" target="_blank" rel="noopener noreferrer">Gamify Stencil Dwarf on Cloud for Democratizing Scientific Computing</a>. Kun Li, Zhichun Li, Yuetao Chen, Zixuan Wang, Yiwei Zhang, Liang Yuan, Haipeng Jia, Yunquan Zhang, Ting Cao*, Mao Yang.</p>
</li>
</ul>
<h6 id="-mobile-platform-resource-scheduling-"><strong>Mobile Platform Resource Scheduling</strong></h6>
<p>Advisor: Prof. Lei Liu | Institute of Computing Technology, Chinese Academy of Sciences</p>
<p>It is called MobiRL, a reinforcement learning-based resource scheduler for mobile systems.  It uses a DDPG model to dynamically adjust the upper and lower frequency limits of the CPU's different clusters and the GPU on mobile devices, in order to achieve the effect of simultaneously reducing frame loss rate and power consumption.</p>
<ul>
<li>Implemented a resource scheduling framework for Android devices using the Deep Deterministic Policy Gradient (DDPG) model to optimize performance.</li>
<li>Designed a piecewise reward function that optimizes energy consumption while limiting frame loss rate, ensuring both efficient use of resources and a high-quality user experience.</li>
</ul>
<h6 id="-intelligent-resource-scheduling-for-co-located-services-"><strong>Intelligent Resource Scheduling for Co-located Services</strong></h6>
<p>Advisor: Prof. Lei Liu | Institute of Computing Technology, Chinese Academy of Sciences</p>
<p>It is called OSML which employs multiple ML models to work collaboratively to predict QoS variations, shepherd the scheduling, and recover from QoS violations in complicated co-location services. Experimental results show that OSML supports higher loads and meets QoS targets with lower scheduling overheads and shorter convergence time than previous studies.</p>
<ul>
<li>Divided the DQN model into two parts to prevent incorrect scheduling decisions and ensure the QoS.</li>
<li>Designed a resource sharing policy, such as shared cacheline, to optimize resource utilization across co-located services.</li>
<li>Tuned PARTIES (ASPLOS '19) and CLITE (HPCA '20) for the evaluation and collected and annotated program resource allocation data.</li>
<li>
<strong>[FAST 2023]</strong> <a href="https://www.usenix.org/conference/fast23/presentation/liu" target="_blank" rel="noopener noreferrer">Intelligent Resource Scheduling for Co-located Latency-critical Services: A Multi-Model Collaborative Learning Approach</a>. Lei Liu*, Xinglei Dou, Yuetao Chen.</li>
</ul>
<h6 id="-nvm-aware-thread-scheduling-approach-on-numa-systems-"><strong>NVM‑aware thread scheduling approach on NUMA systems</strong></h6>
<p>Advisor: Prof. Lei Liu | Institute of Computing Technology, Chinese Academy of Sciences</p>
<p>It is an NVM-aware thread scheduling approach for NUMA systems with hybrid memory, utilizing the LinUCB algorithm to guide scheduling decisions and reduce program execution time by up to 59.9\%.</p>
<ul>
<li>Found the significant difference in local and remote access bandwidth between NVM and DRAM led to performance loss for existing schedulers.</li>
<li>Carefully selected appropriate features and used LinUCB to guide thread scheduling, resulting in improved performance.</li>
<li>
<strong>[CCF THPC]</strong> <a href="https://link.springer.com/article/10.1007/s42514-022-00110-2" target="_blank" rel="noopener noreferrer">Smart Scheduler: an Adaptive NVM-Aware Thread Scheduling Approach on NUMA Systems</a>. Yuetao Chen, Keni Qiu, Li Chen, Haipeng Jia, Yunquan Zhang, Limin Xiao, Lei Liu*.</li>
</ul>
<h6 id="-fast-fourier-transforms-library-"><strong>Fast Fourier Transforms Library</strong></h6>
<p>Advisor: Prof. Haipeng Jia | Institute of Computing Technology, Chinese Academy of Sciences</p>
<ul>
<li>Discovered the changing pattern of FFT algorithm with base 2.</li>
<li>Automatically generated C language codes for FFT algorithm with base 2.</li>
</ul>


 
    <div class="social">
      <div class="contact-icons">
        <a href="mailto:%63%68%65%6E%79%75%65%74%61%6F%32%31%73@%69%63%74.%61%63.%63%6E" title="email"><i class="fas fa-envelope"></i></a>


















<a href="www.chenyuetao.tech/feed.xml" title="RSS Feed"><i class="fas fa-rss-square"></i></a>

      </div>
      <div class="contact-note"></div>
    </div>
     
   

</div>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container">
    © Copyright 2023 Yuetao  Chen.
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

    
    
    Last updated: May 06, 2023.
    
  </div>
  <!-- <a href="https://www.easycounter.com/">
    <img src="https://www.easycounter.com/counter.php?jindongwang" border="0" alt="Hit Counter"></a> <I>unique
    visitors since 2016</I>
<br>
<script type="text/javascript">
    var sc_project = 11393308;
    var sc_invisible = 0;
    var sc_security = "33768b56";
    var scJsHost = (("https:" == document.location.protocol) ?
        "https://secure." : "http://www.");
    document.write("<sc" + "ript type='text/javascript' src='" +
        scJsHost +
        "statcounter.com/counter/counter.js'></" + "script>");
</script>
<noscript>
    <div class="statcounter"><a title="web analytics" href="http://statcounter.com/" target="_blank"><img
                class="statcounter" src="//c.statcounter.com/11393308/0/33768b56/0/" alt="web
analytics"></a></div>
</noscript> -->
</footer>



  </body>

  <!-- jQuery -->
<script src="/assets/js/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="/assets/js/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="/assets/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="/assets/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  

  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

  
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-M83GM6QKSD"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-M83GM6QKSD');
  </script>

</html>
